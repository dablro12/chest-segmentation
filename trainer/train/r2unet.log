2024-05-12 23:40:05.566985: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-12 23:40:05.588473: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-12 23:40:05.639872: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-12 23:40:06.732856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
wandb: Currently logged in as: dablro1232. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /home/eiden/eiden/chest-segmentation/src/trainer/train/wandb/run-20240512_234011-9b19t7p3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-pond-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/dablro1232/Chest-segmentation
wandb: üöÄ View run at https://wandb.ai/dablro1232/Chest-segmentation/runs/9b19t7p3
/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
CUDA Status : cuda
Model: R2U_Net loaded successfully!! | pretrained : False
  0%|          | 0/1000 [00:00<?, ?it/s]  0%|          | 0/1000 [00:07<?, ?it/s]
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.021 MB uploadedwandb: | 0.008 MB of 0.021 MB uploadedwandb: / 0.021 MB of 0.021 MB uploadedwandb: üöÄ View run summer-pond-25 at: https://wandb.ai/dablro1232/Chest-segmentation/runs/9b19t7p3
wandb: Ô∏è‚ö° View job at https://wandb.ai/dablro1232/Chest-segmentation/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3MzMwNzAxNQ==/version_details/v5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240512_234011-9b19t7p3/logs
Traceback (most recent call last):
  File "./run.py", line 12, in <module>
    main()
  File "./run.py", line 9, in main
    trainer.fit()
  File "/home/eiden/eiden/chest-segmentation/src/trainer/train/train.py", line 147, in fit
    outputs = self.model(images)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/eiden/eiden/chest-segmentation/src/trainer/train/../model/models.py", line 70, in forward
    d2 = self.Up_RRCNN2(d2)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/eiden/eiden/chest-segmentation/src/trainer/train/../model/modules/__init__.py", line 36, in forward
    x1 = self.RCNN(x)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/eiden/anaconda3/envs/eiden/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/eiden/eiden/chest-segmentation/src/trainer/train/../model/modules/__init__.py", line 21, in forward
    x1 = self.conv(x+x1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 23.60 GiB of which 4.06 MiB is free. Process 837080 has 3.20 GiB memory in use. Process 839305 has 2.11 GiB memory in use. Process 840111 has 1.87 GiB memory in use. Process 841116 has 2.00 GiB memory in use. Process 842100 has 3.89 GiB memory in use. Including non-PyTorch memory, this process has 10.28 GiB memory in use. Of the allocated memory 9.71 GiB is allocated by PyTorch, and 125.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
